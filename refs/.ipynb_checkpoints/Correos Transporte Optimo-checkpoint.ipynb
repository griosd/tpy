{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correo Joaquín Felipe Julio (05/08/2017)\n",
    "Estimados,\n",
    "\n",
    "Espero que estén muy bien. En mi investigación de TGP llegué a unos trabajos muy ad-hoc del uso del formalismo de transporte óptimo aplicado para inferencia bayesiana. Los tres trabajos que más destaco son:\n",
    "\n",
    "An introduction to sampling via measure transport (2016)\n",
    "Youssef Marzouk, Tarek Moselhy, Matthew Parno, Alessio Spantini\n",
    "    https://arxiv.org/abs/1602.05023\n",
    "\n",
    "Bayesian Inference with Optimal Maps (2011)\n",
    "Tarek A. El Moselhy, Youssef M. Marzouk\n",
    "    https://arxiv.org/abs/1109.1516\n",
    "\n",
    "Transport maps for accelerated Bayesian computation (2015)\n",
    "Matthew Parno\n",
    "    https://dspace.mit.edu/bitstream/handle/1721.1/97263/910630186-MIT.pdf?sequence=1\n",
    "\n",
    "\n",
    "Veo que la intersección de ambas áreas es bastante interesante, ya que mientras MCMC e Inferencia Variacional son los enfoques más conocidos en inferencia bayesiana, el uso de Transport Maps es considerado un tercer enfoque, novedoso y eficiente, que está alineado con la idea de TGP.  \n",
    "\n",
    "\n",
    "Saludos\n",
    "\n",
    "\n",
    "Gonzalo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TGP: Transport Gaussian Processes (14/08/2017)\n",
    "El fin es construir procesos estocásticos no paramétricos que se puedan utilizar como modelos bayesianos predictivos para contextos de machine learning, que sean más expresivos que los procesos guassianos (GP) pero que conserven las buenas propiedades para su entrenamiento y predicción. La idea es utilizar las herramientas de transporte óptimo para nuestro fin de la siguiente forma: a partir de un GP de referencia, deseamos encontrar (entrenar) una transformación (transporte) que transporte el GP al proceso estocástico target, minimizando algún costo ad-hoc al problema. En papers anteriores se han utilizado transportes en el contexto de inferencia bayesiana, pero siempre donde la dimensión es fija y no incluyen un costo de transporte. A continuación comentaré cada página de mis notas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T02:57:14.737709Z",
     "start_time": "2017-08-19T02:57:14.733020Z"
    },
    "collapsed": true
   },
   "source": [
    "1. El problema de transporte original lo reescribo como una versión regularizada, donde la restricción de la marginal target se suma al funcional a optimizar, siguiendo la idea de los multiplicadores de Lagrange. Para comparar las distribuciones se puede utilizar cualquier divergencia positiva, con tal que cumple que $D(p,q) = 0 \\Leftrightarrow  p = q$. En nuestro caso utilizamos la divergencia de Kullback–Leibler $D_{KL}(p,q) = \\int p \\ln \\frac{p}{q}$, pero hay 4 formas diferentes de utilizarla (por su asimetría y la invertibilidad del transporte).\n",
    "\n",
    "2. En nuestro contexto de predicción, la distribución objetivo es la distribución predictiva real, la cual no tenemos acceso a evaluarla, pero si tenemos acceso a muestras (datos reales). Esto nos permite realizar una aproximación de monte carlo a una de las integrales de KL, mientras que el otro término es irrelevante para el problema de optimización. El costo de transporte también puede ser aproximado utilizando estas muestras, obteniendo así un funcional explícito a optimizar.\n",
    "\n",
    "3. Como el multiplicador de Lagrange es siempre positivo (cuando tiene a infinito, el problema regularizado converge al problema original), es posible traspasar la constante al término del costo de transporte, reinterpretando este término como el regularizador del problema. En la siguiente parte estoy interesado en construir transportes no deterministicos que, además del GP de referencia $x$ tiene acceso a una fuente aleatoria independiente $\\alpha$, de modo que la distribución de $y$ y en costo se debe marginalizar (integrar) la variable $\\alpha$. Un ejemplo es cuando multiplico una gaussiana por la raiz cuadrada de una gamma inversa, el proceso resultante es student-t. \n",
    "\n",
    "4. Definiendo notación de todos los elementos, donde $T$ es un transporte y $S$ es su inversa. Extendemos esta notación para los transportes no deterministas.\n",
    "5. Podemos notar que podría darse el caso que $x$ dependa de $\\alpha$ o viceversa, es decir el caso que las fuentes no son independientes. Se revisan las fórmulas de la función de probabilidades y su densidad para el caso independiente. \n",
    "6. Se plantea el problema de transporte óptimo en nuestro contexto, es decir en términos de $x$ y de $\\alpha$.\n",
    "7. Escribo el problema de transporte optimo de forma general, y describo los elementos en el contexto de GPs: la referencia $x$ es gaussiana, de la objetivo $y$ tengo acceso a $n$ muestras, puedo evaluar y generar muestras de $\\alpha$ de forma fácil, y la evaluación de $T$ y $S$ es fácil.\n",
    "8. El costo de transporte puede escribirse en términos de $x$ o de $y$, por lo que se explicitan las 4 aproximaciones de monte carlo, según si se puede integrar con respecto a $\\alpha$ de forma explícita o no, y si se generar muestras desde $x$ o se utilizan las observaciones $y$\n",
    "9. Se muestran las 4 formas diferentes de descomponer la KL, mostrando que en 3 casos es necesario evaluar la densidad objetiva, mientras que en el primer caso no es necesario evaluar ya que ese término es constante en el problema de optimización.\n",
    "10. Se escribe el problema de transporte regularizado por entropía, término que se aproxima por monte carlo, y utilizando Jensen se entrega una cota inferior más simple de evaluar numéricamente.\n",
    "11. Muestro que el caso trivial, con costo cero, transporte identidad y determinista, el funcional a optimizar es exactamente el mismo que en el caso GP standard, que corresponde a la negative log-likelihood (NLL). Luego extiendo el caso con una transformación no lineal aplicada a todas las coordenadas, y el funcional es exactamente el caso NLL de warped GP. En el tercer caso se toma un transporte lineal $T = \\sqrt(\\alpha)x$ con $\\alpha$ una distribución gamma inversa, entonces el funcional obtenido coincide con el caso NLL de Student-t process.\n",
    "12. En el cuarto caso, tomo que mi medida de referencia es un proceso gaussiano de ruido blanco, y construyo el transporte $T$ a partir de un kernel de covarianza, de modo que el funcional es el mismo que el GP standard, pero con la diferencia que la medida de referencia esta fija. En el quinto caso tomamos como función de costo de transporte $C(x,y)$ a la norma. Mostramos la diferencia entre considerar una distribución de referencia fija (costo positivo) versus una entrenable con el kernel (costo cero). Definimos un ejemplo de transporte de media y varianza.\n",
    "13. Evaluo el costo en este caso y realizo una aproximación de monte carlo utilizando las observaciones, obteniendo un funcional explícito a optimizar, donde podemos notar que el costo penaliza medias diferentes a 0 y varianzas de 1. Descompogo un kernel de covarianza en su función de varianza y su kernel de correlación, y menciono que media y varianza definen la marginal, la correlación define la copula.\n",
    "14. Con esta descomposición, se obtiene que el transporte del kernel se puede expresar como la composición del transporte de varianza y el transporte de correlación (y conmutan). Defino un transporte aditivo de la media, y mostramos que la composición de estos tres transportes corresponde al transporte asociado a un GP desde un proceso de ruido blanco. Si consideramos el transporte lineal estocástico con fuente gamma inversa, entonces mostramos la composición de transportes que generan un Student-t process.\n",
    "15. Muestro las descomposiciones de los transportes asociados a warped GP y warped Student-t, ambas agregando un el transporte inducido por un mappeo no lineal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T04:39:29.781948Z",
     "start_time": "2017-08-19T04:39:29.775591Z"
    }
   },
   "source": [
    "# Reunión Joaquín Felipe (16/08/2017)\n",
    "A continuación describiré cada uno de los puntos de trabajos futuros:\n",
    "1. Agregar el caso de Skew Gaussian Processes.\n",
    "2. Buscar otras transformadas que no sean triangulares, tal como es el caso GPMM.\n",
    "3. Definir mejores costos según una perspectiva estadística o numérica, si hay un costo natural.\n",
    "4. Familias de transportes que sea el problema ad-hoc, hasta donde se puede llegar (deep).\n",
    "5. En termino de medida, el funcional a optimizar es convexo, el problema de la no convexidad aparece al parametrizar las distribuciones. Buscar si es posible aprovecharse de este hecho para encontrar mejores optimos ¿ puedo generar a partir de mis iteraciones una distribución mejor? Enfoque bayesiano y model average.\n",
    "6. Revisar sobre flujo gradiente en el paper de Otto y Kinder del año 1998. Tal vez ayuda a encontrar un algoritmo de gradiente en el espacio de medida ($W^{2}$ u otro costo).\n",
    "7. Ver la complejidad del transporte según la cantidad de fuentes aleatorias, como considerar dos gaussianas por cada coordenada.\n",
    "8. Definir bien los conceptos de prior y posterior, dar noción de costo. Ver relación con BIC e AIK.\n",
    "9. Revisar si el tema de kernel embedding cabe en este contexto.\n",
    "10. Estudiar bien el paper de clasificación con transporte óptimo.\n",
    "11. Revisar bien la razón de tomar transportes triangulares, si es por un tema algoritmico, numérico, geométrico, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correo Joaquín Felipe Julio (19/08/2017)\n",
    "Estimados, les adjunto mis notas sobre Transport Gaussian Processes, basados en scanners de mi cuaderno con las fórmulas y un documento que las explica y traduce los trabajos futuros. Después de las reuniones con Joaquín y Felipe, y el intercambio de papers con Julio, voy a comentar los puntos tratados por Joaquín:\n",
    "\n",
    "1 - En el marco de transporte óptimo fue posible obtener todos los procesos estocásticos que por sus buenas propiedades se pueden utilizar como modelos predictivos no parametricos: GPs, warped GPs, Student-t process. El caso standard es cuando el costo de transporte es cero. En la construcción del funcional a optimizar, el costo de transporte se interpreta como un regularizador, lo que en términos algoritmicos nos permite obtener modelos de zonas de menor costo, bajo algún criterio que depende de lo que se quiera optimizar. Podemos pensar el costo como la cantidad de fuentes aleatorias para generar la salida, el costo de simulación, u otro costo de complejidad como BIC y AIK.\n",
    "\n",
    "2 - Los papers que les envié solo toman la inspiración de transporte optimo ya que durante todo el desarrollo coincideran costo nulo. Nuestro enfoque permite meter información adicional al problema.\n",
    "\n",
    "3 - El tema de las transformaciones triangulares es necesario entender bien que significa desde en términos de la estructura de dependencia del modelo, ya que por completitud es capaz de definir todos los procesos mencionados en un inicio. Es posible encontrar la descomposición de transportes asociada a cada uno de los procesos, donde cada una de las transformaciones controla un momento diferente del proceso: marginal (media, varianza) y copula (correlación, dependencia en las colas). Una transformación a estudiar es la asociada a GPMM.\n",
    "\n",
    "4 - Efectivamente el componer transportes se puede observar como una estructura deep o jerárquica, pero donde cada cada tiene una interpretación directa (un momento del proceso). Estas capas están desarrollas al final de las notas. Tengo que estudiar aún más el paper de Julio, ya que creo que me falta un background de notación que integrar primero, pero me da la impresión que la estructura casual tiene una relación con la estructura triangular del mapa.\n",
    "\n",
    "5 - Creo que con los documentos enviados se ordenan varios conceptos de transporte óptimo y define un hilo conductor adecuado en el contexto de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T06:51:09.459555Z",
     "start_time": "2017-10-12T06:51:09.455069Z"
    }
   },
   "source": [
    "# Reunión Joaquín (13/09/2017)\n",
    "Reunión previa a operación:\n",
    "\n",
    "1. Segun un costo de transporte, se puede definir las marginales y la copula objetivos\n",
    "2. No coinciderar el dominio todos los reales, sino los enteros o un intervalo (para costo finito)\n",
    "3. Aplicar resultados de OT (e.x. Gaussian OT martingala -> proceso elliptico)\n",
    "4. Asociar transformacion al problema que resuelve, problema no estandard (con restriccion, penalización, familia marginales) equivalente al probvlema estandard. Original <-> Regularizado <-> No estandard <-> Clasico con restricciones\n",
    "5. Restringir/regularizar una copula (orden 2) ley de los pares sea la empirica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avances (12/10/2017)\n",
    "En estas semanas se han realizado los siguientes avances de tareas:\n",
    "\n",
    "1. Se confirmó que Skew Gaussian Processes cabe dentro de nuestro framework de modelacion.\n",
    "2. Se estudió bien el paper de clasificación con transporte óptimo, y se ve una posible forma de calcular el gradiente del costo con respecto la distribución, a través de un método de punto fijo.\n",
    "3. Formula explícita para el costo de Wasserstein $W_2$ entre dos gaussianas y el transporte óptimo.\n",
    "\n",
    "Se avanzó en los siguientes otros temas:\n",
    "\n",
    "1. Se terminó el paper CWGP\n",
    "2. Revisión de contexto para probar la optimalidad de WGP\n",
    "3. Programación en G3py del modelo Transport Gaussian Processes (TGP), donde se definieron transformaciones bases: sumar media, multiplicar media, mapping por coordenada y cholesky de un kernel. Se chequeo que logp coincide en caso WGP.\n",
    "4. Derivación de algoritmo para calcular la distribución posterior de un TGP dado las observaciones. Se demostró que distribución coincide en caso WGP.\n",
    "\n",
    "Se desea avanzar en los siguientes aspectos:\n",
    "\n",
    "1. Programar en G3py la distribución posterior de TGP\n",
    "2. Composicion de kernel/mapping: poder expresivo (copula) depende del orden?\n",
    "3. Transportes no triangulares (caso GPMM), revisar formular de la determinante en matrices por bloques\n",
    "4. Revisar si la restricción con los datos pueden tomar las marginales, las bivariadas, las multivariadas,por si se puede separar el problema en etapas (marginales + copula + coupling).\n",
    "5. Buscar costos de transportes finitos (para familias de procesos/dominios)\n",
    "6. Relación entre costo y composición de transportes\n",
    "7. Plantear problema multidimensional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correo Joaquín Felipe Julio - Bayesian Wasserstein Barycenters - 21/12/2017\n",
    "\n",
    "Estimados,\n",
    "    Tal como he conversado con cada uno de ustedes por separado, en mi pasantía en Viena salió la idea de aplicar la teoría de baricentros usando la métrica de Wasserstein para calcular un modelo predictivo 'promedio'. Si bien la teoria de baricentros no es nueva, siempre se habia considerado el caso de una cantidad finitas de medidas dadas a promediar, mientras que en el enfoque bayesiano uno busca una esperanza de las distribuciones predictivas, dada la medida sobre estas distribuciones entretegada por la ley posterior de los hiperparámetros dados los datos. Ya revisé y este modelo 'entrenado' no coincide en general con el de máxima verosimilitud ni con el de model average, es un paradigma diferente.\n",
    "    \n",
    "La existencia y consistencia (continuidad) de este problema se estudió recién el 2015 en el siguiente trabajo:\n",
    "\n",
    "** Existence and consistency of Wasserstein barycenters - Thibaut Le Gouic, Jean-Michel Loubes - https://link.springer.com/article/10.1007/s00440-016-0727-z **\n",
    "\n",
    "Este trabajo demuestra propiedades para el caso p-Wasserstein en general, mientras que otros autores se han concentrado en el caso 2-Wasserstein donde se puede caracterizar de mejor forma el baricentro. En el siguiente trabajo\n",
    "\n",
    "** Wide Consensus for Parallelized Inference - P. C. Álvarez-Esteban, E. del Barrio, J.A. Cuesta-Albertos, C. Matrán - https://arxiv.org/abs/1511.05350 **\n",
    "\n",
    "Los autores definien una familia de distribuciones que es cerrada para baricentros (con 2-Wasserstein), además de desarrollar un algoritmo de punto fijo para calcularlo y encontrar algunas propiedades de optimalidad. Esta familia es lo suficiente general que permite definir el baricentro para Gaussianas, punto de partida para el trabajo presentado en NIPS de este año\n",
    "\n",
    "** Learning from uncertain curves: The 2-Wasserstein metric for Gaussian processes - Anton Mallasto and Aasa Feragen - https://papers.nips.cc/paper/7149-learning-from-uncertain-curves-the-2-wasserstein-metric-for-gaussian-processes **\n",
    " \n",
    "el cual extiende el resultado para procesos gaussiano mostrando que se puede hacer una aproximación finita-dimensional. Como la estimación  del baricentro real debe realizarse a partir de muestras empíricas de distribuciones, es interesante estudiar la rapidez de convergencia de esta estimación o poder construir \"conjuntos de confianza\" tal como se desarrolla en \n",
    "\n",
    "** Construction of Non-asymptotic Confidence Sets in 2-Wasserstein Space - Johannes Ebert, Vladimir Spokoiny, Alexandra Suvorikova - https://arxiv.org/abs/1511.05350 **\n",
    "\n",
    "Otros trabajos han extendido estos resultados a problemas más generales, como es el caso de\n",
    "\n",
    "** Penalized Barycenters in the Wasserstein Space - Jérémie Bigot, Elsa Cazelles, Nicolas Papadakis - https://hal.archives-ouvertes.fr/hal-01564007/ **\n",
    "\n",
    "donde la idea es agregar una componente de penalización que permite encontrar más rápido el baricentro (como el trabajo de Cuturi en el caso discreto) para luego bajar el nivel de regularización para converger al baricentro real.\n",
    "\n",
    "Realicé una búsqueda exhautiva de la bibliografía y he estado estudiandola, para ver que es lo que hay y que es lo que no. Lo bueno es que hay harto espacio, sobre todo en Machine Learning, y desde un aspecto más teórico es definir clases más generales que sean cerradas por baricentros, o caracterizarlos, ver la rapidez de convergencia de la estimación empírica del baricentro al real, encontrar conjuntos de confianza, etc. Mi intención es probar esto para GPs, Warped GPs y algun modelo más general, desarrollar un algoritmo para calcular el modelo baricentro, compararlo con el modelo de maxima verosimilitud y model average, utilizar algunas técnicas de regularización para mejorar performance y/o precisión, y espero poder caracterizar este baricentro en término de sus marginales y su cópula. Mi intuición me dice que hay alguna forma de primero encontrar las marginales y luego la cópula, y que este procedimiento es consistente con el baricentro real, pero bueno, esto es sólo una intuición.\n",
    "\n",
    "Saludos\n",
    "\n",
    "Gonzalo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correo Julio a Joaquin - 19/01/2018\n",
    "\n",
    "Hola Joaquín, Gonzalo me pidió que te escribiera.\n",
    "La próxima semana tengo bastante libre de Lunes a Jueves, así que si te calza un día fijamos reunión.\n",
    "\n",
    "Gonzalo está escribiendo un resumen, y lo más importante, una especie de 'proyecto' para que todos entiendan en qué estamos. En resumidas cuentas el estado del arte es el siguiente:\n",
    "\n",
    "+ Idea para Machine Learning:\n",
    "en el contexto Bayesiano, hacer un baricentro de las medidas predictivas dado los parámetros (estos últimos ya fueron entrenados, dados los datos). Es decir,dados mis datos tengo una distribución 'M' sobre los parámetros (contrario a max verosimilitud, donde te casas con un parámetro) que denoto m. Si 'q_m(dx)' es mi medida predictiva dado el parámetro M=m, entonces nuestra propuesta es tomar como medida predictiva el baricentro de los q_m (donde a cada q_m le doy peso M(dm) ). Esto es distinto a inferencia variacional, y parece ser nuevo en el área. Notar que M(dm) no tiene por qué ser discreta.\n",
    "\n",
    "+ Baricentros en general: \n",
    "parece ser que el único método numérico propuesto para baricentros es uno de punto fijos. Nosotros le dimos vuelta y resultó que ese método se puede interpretar como el método de gradiente (ie. máximo descenso) en espacio de Wasserstein para el funcional $mu \\mapsto V(mu) : = \\int W_2^2(mu,q_m) dM(m).$ Gradiente se entiende acá en el sentido 'tipo Riemanniano' de transporte óptimo. Con esta interpretación, podemos plantear otros métodos de primer orden (es decir que sólo involucren evaluaciones de V y su gradiente) que a priori debiesen ser más rápidos que el método de punto fijo (por ejemplo, gradiente con paso variable, o gradiente acelerado de Nesterov). Sería choro poder demostrar, como es el caso de optimización convexa en R^n, que el método gradiente acelerado que proponemos es el más rápido de todos los métodos de primer orden pa calcular baricentros.\n",
    "\n",
    "+ Baricentros en casos especiales:\n",
    "resulta que hay familias F de medidas de probabilidad, tales que si q_m pertence a F pa todo m, entonces el baricentro de los q_m con pesos M(dm) también pertenece a F. Descubrir más familias F con esta propiedad ya es un tema (por ejemplo, nadie ha visto qué pasa en el caso de T-students, o de la familia elíptica ... en general, qué pasa si se conoce el cópula de la familia, etc). Otra cosa: cómo se ven los métodos numéricos propuestos en el párrafo anterior cuando trabajamos en una familia concreta F.\n",
    "\n",
    "Ya, esto es como un resumen no más, pero ya se vienen más detalles. Más que todo para reafirmar lo que conversaste con Gonzalo x Skype: que nos meteremos de lleno a estudiar métodos para baricentros y que esto es relevante matemáticamente así como pa la aplicación a ML.\n",
    "\n",
    "Una última cosa que te puede interesar: no hay buenos resultados en la literatura para 'baricentros empíricos.' Es decir, existen resultados que dicen que si sampleo {m_1, m_2,...} a partir de M(dm), entonces la secuencia (aleatoria) de baricentros b_n = baricentro( q_(m_1),...,q_(m_n) ) converge en Wasserstein c.s. al baricentro real de los q_m (con pesos M(dm) ). Esto es una ley de los grandes números. Lo que no existe es resultados generales de velocidad de convergencia, concentración, etc. Esto lo dejaríamos fuera de este proyecto, para acotar la cosa.\n",
    "\n",
    "Estamos hablando Sl2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correo Joaquin a Julio, Gonzalo - 22/01/2018\n",
    "hola julio y gonzalo\n",
    "\n",
    "disculpa lo del viernes, pretendia terminar y mandar  antes de hablar un carta de recomendacion a alguien para oxford,  y el sistema estaba caído (al final la pude mandar bien al filo….)\n",
    "\n",
    "gracias por el mail detallado.\n",
    "\n",
    "me parece super bueno que hayan identificado lo de Cuesta Albertos con un método gradiente, lo demás  que detallas me parece super bien y  lógico como programa\n",
    "\n",
    "Me quedan eso si un par de puntos dando vuelta: \n",
    "\n",
    "1 - mas alla de que es natural buscar algo mas robusto que el  MAP como ley predictiva por motivos que  hemos hablado ,  me gustaria encontrarle alguna propiedad al barycentro de la ley a posteriori sobre los modelos, c/r a la muestra. \n",
    "\n",
    "O sea, si bien el MAP sabemos que no es muy bueno, al menos hace sentido intuitivo en relación con la muestra ( el parámetro mas verosímil….)  pero no logro visualizar que rol “optimo”  (en el algún  sentido) puede tener el baricentro en este caso.\n",
    "\n",
    " Entendiendo que los baricentros hacen mas sentido c/r a la geometría del espacio de wasserstein que por ejemplo a tomar simplemente un promedio de modelos,  creo que desde ya la pregunta tiene sentido para este ultimo caso (donde estaríamos hablando de la ley predictiva  promedio c/r a la posteriori), e incluso ahí, no veo bien la respuesta.  Pero quizás algo se sabe al respecto. \n",
    "\n",
    "Por ejemplo, cabe preguntarse si es el baricentro,  en un cierto espacio  (e.g. la “envoltura convexa de las leyes productivas del modelo”, en sentido Wasserstein) aquella ley  que tiene menor MSE condicional a la muestra, medido en distancia de Wasserstein, a la ley empírica?  Me parece que no … pero por ejemlo si uno quieres minimizar ese MSE en W_2 condicional a la muestra, puede acotarlo por desiguladad triangular (salvo constante…) por el “sesgo”,  dado por la distancia entre el baricentro y la ley empírica (lo que, condicionalmente a la muestra, es algo determinista) mas la “varianza” , que podemos decir que dada por la media de la distancia^2 al baricentro, de todas las leyes predictivas .  Sin embargo, los 2 términos están acoplados…. pero no parece ser mucho mas difícil  (de forma al menos) de estudiar la minimzacion de esa suma, que la requerida para encontrar el barcientro solito…. creo, o no?\n",
    "\n",
    "Visto así,  en el fondo uno estar encontrado una proyección de la ley empírica, a unaley en el espacio generado por las leyes predictivas...\n",
    "\n",
    "\n",
    "-  me parece que todo lo que están planteando efectivamente “responde” a algo que te comente a ti y gonzalo  en algún momento (aunque obviamente no habia pillado una formulación precisa), vale decir,   si usando la estructura de problema convexo del transporte optimo, uno podía patear el problema de optimizar en los parámetros para encontrar el mejor modelo explicativo (como las transformaciones de gonzalo) a un problema en el espacio de leyes predictitvas codificadas por esos parámetros, y que en base a eso uno pueda usar algoritmos  basados en esa interpretación en términos de OT.  En realidad, casi, porque de nuevo, no tengo claro que estamos optimizando  en relación con la muestra, al buscar el baricentro de las leyes preductivas.\n",
    "\n",
    "- Otra cosa: si bien el algoritmo de Cuesta Albertos hace sentido perfecto para una muestra discreta (i.e. nº finito de medidas a quienes encontrarle baricentro) y corresponde a un algoritmo gradiente,   me preguntaba  si al querer calcular uno el baricentro teórico (que minimiza la esperanza de las leyes predictivas  c/r a ley a posteriori de los parametros), no tendria sentido pensar en algo análogo a un gradiente estocastico  , en donde en cada paso uno samplea una v.a. con la ley bajo la cual se calcula la esperanza, y cocina una secuencia de puntos cuya media converge al mínimo de la función (que es una esperanza).  En ese caso, el algoritmo podria hacerse transportando medidas de una en una (dada la formal gradiente de wasserstein) ,  o no?\n",
    "\n",
    "tengo unas preguntas mas, pero hablemos por skype\n",
    "\n",
    "creo que podria mañana en la mañana (entre 8:00 y 12:00 de aqui)\n",
    "\n",
    "saludos\n",
    "\n",
    "Joaquín \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links to Check\n",
    "+ https://en.wikipedia.org/wiki/Gradient_descent\n",
    "+ https://en.wikipedia.org/wiki/Maximum_likelihood_estimation\n",
    "+ https://en.wikipedia.org/wiki/Cramér–Rao_bound\n",
    "+ https://en.wikipedia.org/wiki/Mean_squared_error\n",
    "+ https://en.wikipedia.org/wiki/Consistent_estimator\n",
    "+ https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation\n",
    "+ https://en.wikipedia.org/wiki/Bayes_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
